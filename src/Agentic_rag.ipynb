{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab47b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langgraph langchain transformers sentence-transformers torch\n",
    "%pip install -qU langchain-chroma\n",
    "%pip install huggingface_hub[hf_xet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d97bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f6d104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# Defining agent state\n",
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    retrieved_docs: List[str]\n",
    "    final_answer: str\n",
    "    needs_retrieval: bool\n",
    "\n",
    "# Load Hugging Face LLM\n",
    "model_id = \"microsoft/phi-2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "hf_pipeline = pipeline(\"text-generation\",\n",
    "                       model=model,\n",
    "                       tokenizer=tokenizer,\n",
    "                       max_new_tokens = 300,\n",
    "                       temperature = 0.2\n",
    "                       )\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e1c498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DGY3KOR\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define Embedding Model\n",
    "embedder = HuggingFaceEmbeddings(model_name = \"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Provide the existing chroma vector store path\n",
    "VECTOR_DB_PATH = \"../Data/vectorstore\"\n",
    "vector_store = Chroma(\n",
    "    collection_name= \"pdf_documents\",  # Provide your collection name. Not sure of collection name, use the below code\n",
    "    # print(vector_store._collection.count())\n",
    "    persist_directory= VECTOR_DB_PATH,\n",
    "    embedding_function= embedder\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc475d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCH2021.1 Shapiro_Machine Learning ... 00e6 1 \n",
      "Machine Learning: what is it and what are its components? \n",
      "-- some preliminary observations1 \n",
      " \n",
      "Arnold F. Shapiro \n",
      "Penn State University, Smeal College of Business, University Park, PA 16802, USA \n",
      "Abstract \n",
      "This article focuses on conceptualizing machine learning (ML) concepts.  The general topics \n",
      "covered are supervised learning based on regression and classification, unsupervised \n",
      "learning based on clustering and dimensionality reduction, and rei\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\"What is machine learning\", k=1)\n",
    "print(results[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3999549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    This node is responsible ONLY for retrieval.\n",
    "    It does not generate answers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the user query from agent state\n",
    "    query = state[\"user_query\"]\n",
    "\n",
    "    # Ask vector store for semantically similar chunks\n",
    "    results = vector_store.similarity_search(\n",
    "        query=query,\n",
    "        k=3\n",
    "    )\n",
    "\n",
    "    # Extract raw text from Document objects\n",
    "    retrieved_texts = [doc.page_content for doc in results]\n",
    "\n",
    "    # Return partial state update (LangGraph merges state)\n",
    "    return {\n",
    "        \"retrieved_docs\": retrieved_texts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16978692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will create Decision node. Here it will check whether the RAG itself is enough or other tool needs to be called.\n",
    "def decide_node(state: AgentState):\n",
    "    prompt = f\"\"\"\n",
    "    User request:\n",
    "    {state['user_query']}\n",
    "    Do you need to retrieve external documents to answer this?\n",
    "    Answer only YES or NO.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt).strip().upper()\n",
    "\n",
    "    needs_retrieval = \"YES\" in response\n",
    "\n",
    "    return {\n",
    "        \"needs_retrieval\": needs_retrieval\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd55aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_node(state: AgentState):\n",
    "    context = \"\\n\\n\".join(state.get(\"retrieved_docs\", []))\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Answer the question strictly using the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{state['user_query']}\n",
    "\n",
    "Rules:\n",
    "- If the answer is not present in the context, reply exactly:\n",
    "  \"I do not have enough information to answer this.\"\n",
    "- Do NOT repeat the question.\n",
    "- Do NOT repeat the context.\n",
    "- Give a concise answer.\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # HuggingFace models return full text; extract only the answer\n",
    "    answer = response.split(\"Rules:\")[-1].strip()\n",
    "\n",
    "    return {\n",
    "        \"final_answer\": answer\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0de7ac1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x29d7c58c710>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the LangGraph\n",
    "graph=StateGraph(AgentState)\n",
    "graph.add_node(\"decide\", decide_node)\n",
    "graph.add_node(\"retrieve\", retrieve_node)\n",
    "graph.add_node(\"answer\", answer_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2cb4297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_after_decision(state: AgentState):\n",
    "    if state[\"needs_retrieval\"]:\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        return \"answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccbb1d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x29d7c58c710>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will define control flow\n",
    "graph.set_entry_point(\"decide\")\n",
    "graph.add_conditional_edges(\n",
    "    \"decide\",\n",
    "    route_after_decision,\n",
    "    {\n",
    "        \"retrieve\": \"retrieve\",\n",
    "        \"answer\": \"answer\"\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"retrieve\", \"answer\")\n",
    "graph.add_edge(\"answer\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26a7d749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- If the answer is not present in the context, reply exactly:\n",
      "  \"I do not have enough information to answer this.\"\n",
      "- Do NOT repeat the question.\n",
      "- Do NOT repeat the context.\n",
      "- Give a concise answer.\n",
      "- Do NOT use any external resources.\n",
      "\n",
      "Answer:\n",
      "Machine Learning is a field that combines concepts and results from various disciplines such as statistics, artificial intelligence, philosophy, information theory, biology, cognitive science, computational complexity, and control theory. It aims to develop algorithms and models that enable computers to learn from data and make predictions or decisions without being explicitly programmed.\n",
      "\n",
      "Explanation:\n",
      "Machine Learning is a multidisciplinary field that draws on concepts and results from various disciplines. It involves developing algorithms and models that allow computers to learn from data and make predictions or decisions without being explicitly programmed. This field combines ideas from statistics, artificial intelligence, philosophy, information theory, biology, cognitive science, computational complexity, and control theory.\n",
      "\n",
      "Follow-up exercises:\n",
      "1. Explain the difference between supervised and unsupervised learning in machine learning.\n",
      "2. Provide an example of a real-world application of machine learning.\n",
      "3. Discuss the importance of data in machine learning and how it is used to train models.\n"
     ]
    }
   ],
   "source": [
    "# Compile and Run\n",
    "agent = graph.compile()\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"user_query\": \"What is machine Learning?\"\n",
    "    }\n",
    ")\n",
    "print(result[\"final_answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
